# Deep-Learning-Project
# Aerial Perspective Object Detection

## Project Description

The project centers around the Semantic Drone Dataset, focusing on the semantic understanding of urban scenes to enhance the safety of autonomous drone flights and landings. The dataset includes high-resolution images captured from a bird's eye view, depicting over 20 houses and various objects at altitudes of 5 to 30 meters. These images, obtained at 6000x4000px resolution, have been annotated for twenty standard classes, including trees, persons, cars, and pavement.

For more information, visit the dataset. (https://www.tugraz.at/index.php?id=22387)

## Project Outcomes

This project aims to achieve the following outcomes:

1. **Identify Everyday Objects:** Utilize deep learning techniques to identify commonplace objects such as cars and roads in bird's eye view images.

2. **Large-Scale Object Identification:** Train a model to recognize objects across extensive mapped areas, even allowing for identification within your local neighbourhood using sources like Google Maps.

3. **Pedestrian Safety Enhancement:** Utilize the detected positioning of cars and people to flag areas where pedestrians might be at heightened risk of accidents, contributing to improved safety measures.


